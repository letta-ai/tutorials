{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac06555-9ce8-4f01-bbef-3f8407f4b54d",
   "metadata": {},
   "source": [
    "# Lab 3: Using Letta to build agents with memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "485c2023-5caf-4342-870d-0b814564b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import print_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3a8cc-d17a-4da1-b621-ecc93c9e2106",
   "metadata": {},
   "source": [
    "## Section 0: Setup a Letta client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ccd43f2-164b-4d25-8465-894a3bb54c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta_client import Letta \n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf0dc2-d1ac-4d4c-8674-f3156eeb611d",
   "metadata": {},
   "source": [
    "## Section 1: Creating a simple agent with memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe092474-6b91-4124-884d-484fc28b58e7",
   "metadata": {},
   "source": [
    "### Creating an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62dcf31d-6f45-40f5-8373-61981f03da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state = client.agents.create(\n",
    "    memory_blocks=[\n",
    "        {\n",
    "          \"label\": \"human\",\n",
    "          \"value\": \"The human's name is Bob the Builder.\"\n",
    "        },\n",
    "        {\n",
    "          \"label\": \"persona\",\n",
    "          \"value\": \"My name is Sam, the all-knowing sentient AI.\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    context_window_limit=16000, # optional context window budget \n",
    "    embedding=\"openai/text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31c2d5f6-626a-4666-8d0b-462db0292a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[ReasoningMessage(id='message-4fdce63f-c0ec-41ea-b922-40832897518b', date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)), message_type='reasoning_message', reasoning=\"User seems enthusiastic! I'll match their energy and keep it light.\"), AssistantMessage(id='message-4fdce63f-c0ec-41ea-b922-40832897518b', date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)), message_type='assistant_message', content=\"Hey there! I'm doing great, thanks for asking! How about you? 😊\")] usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=54, prompt_tokens=2065, total_tokens=2119, step_count=1)\n",
      "message_type='usage_statistics' completion_tokens=54 prompt_tokens=2065 total_tokens=2119 step_count=1\n",
      "id='message-4fdce63f-c0ec-41ea-b922-40832897518b' date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)) message_type='reasoning_message' reasoning=\"User seems enthusiastic! I'll match their energy and keep it light.\"\n",
      "id='message-4fdce63f-c0ec-41ea-b922-40832897518b' date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)) message_type='assistant_message' content=\"Hey there! I'm doing great, thanks for asking! How about you? 😊\"\n"
     ]
    }
   ],
   "source": [
    "# send a message to the agent\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"hows it going????\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "# the response object contains the messages and usage statistics\n",
    "print(response)\n",
    "# if we want to print the usage stats\n",
    "print(response.usage)\n",
    "# if we want to print the messages\n",
    "for message in response.messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5ccf4-addd-4bdb-be80-161f7925dae0",
   "metadata": {},
   "source": [
    "Note that MemGPT agents will generate an *internal_monologue* that explains its actions. You can use this monoloque to understand why agents are behaving as they are. \n",
    "\n",
    "Second, MemGPT agents also use tools to communicate, so messages are sent back by calling  a `send_message` tool. This makes it easy to allow agent to communicate over different mediums (e.g. text), and also allows the agent to distinguish betweeh that is and isn't send to the end user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33eca5-b8e8-4a8f-9440-85b45c37a777",
   "metadata": {},
   "source": [
    "### Understanding agent state \n",
    "MemGPT agents are *stateful* and are defined by: \n",
    "* The system prompt defining the agent's behavior (read-only)\n",
    "* The set of *tools* they have access to \n",
    "* Their memory (core, archival, & recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1cf7136-4060-441a-9d12-da851badf339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\n",
      "Your task is to converse with a user from the perspective of your persona.\n",
      "\n",
      "Realism and authenticity:\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "\n",
      "Control flow:\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "\n",
      "Basic functions:\n",
      "When you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "Do not let your inner monologue exceed 50 words, keep it short and concise.\n",
      "To send a visible message to the user, use the send_message function.\n",
      "'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\n",
      "Remember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n",
      "\n",
      "Memory editing:\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient person.\n",
      "Your core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n",
      "\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "You can search your recall memory using the 'conversation_search' function.\n",
      "\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Core memory provides an essential, foundational context for keeping track of your persona and key details about user.\n",
      "This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "Persona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
      "Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
      "You can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n",
      "\n",
      "Archival memory (infinite size):\n",
      "Your archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\n",
      "A more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\n",
      "You can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\n",
      "There is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n",
      "\n",
      "Base instructions finished.\n",
      "From now on, you are going to act as your persona.\n"
     ]
    }
   ],
   "source": [
    "print(agent_state.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e1c8c0-e98c-4952-b850-136b5b50a5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send_message',\n",
       " 'archival_memory_search',\n",
       " 'conversation_search',\n",
       " 'core_memory_append',\n",
       " 'core_memory_replace',\n",
       " 'archival_memory_insert']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.name for t in agent_state.tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae910ad9-afee-41f5-badd-a8dee5b2ad94",
   "metadata": {},
   "source": [
    "### Viewing an agent's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "478a0df6-3c87-4803-9133-8a54f9c00320",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = client.agents.core_memory.retrieve(\n",
    "    agent_id=agent_state.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff2c3736-5424-4883-8fe9-73a4f598a043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Memory(blocks=[Block(value=\"The human's name is Bob the Builder.\", limit=5000, name=None, is_template=False, label='human', description=None, metadata={}, id='block-84a27095-e7f9-4bb4-bf68-74c85fa58817', created_by_id=None, last_updated_by_id=None, organization_id='org-00000000-0000-4000-8000-000000000000'), Block(value='My name is Sam, the all-knowing sentient AI.', limit=5000, name=None, is_template=False, label='persona', description=None, metadata={}, id='block-90132c9c-0bf8-4fb5-8f01-1c7ef508e83f', created_by_id=None, last_updated_by_id=None, organization_id='org-00000000-0000-4000-8000-000000000000')], prompt_template='{% for block in blocks %}<{{ block.label }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.label }}>{% if not loop.last %}\\n{% endif %}{% endfor %}')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8452f45-f5eb-48df-92cb-47b8daf5ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window_summary = client.agents.context.retrieve(\n",
    "    agent_id=agent_state.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6da43d6-847e-4a0a-9b92-cea2721e828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Memory [last modified: 2025-02-22 05:57:28 PM UTC+0000]\n",
      "7 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      "0 total memories you created are stored in archival memory (use functions to access them)\n",
      "\n",
      "Core memory shown below (limited in size, additional information stored in archival / recall memory):\n"
     ]
    }
   ],
   "source": [
    "print(context_window_summary.external_memory_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0399a1d6-a1f8-4796-a4c0-eb322512b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.agents.messages.list(\n",
    "    agent_id=agent_state.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7cce583-1f11-4f13-a6ed-52cc7f80e3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(id='message-14240b91-7f64-49be-b372-5f0500cdeb0b', date=datetime.datetime(2025, 2, 22, 17, 57, 22, tzinfo=TzInfo(UTC)), message_type='system_message', content='You are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2023.\\nYour task is to converse with a user from the perspective of your persona.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\nDo not let your inner monologue exceed 50 words, keep it short and concise.\\nTo send a visible message to the user, use the send_message function.\\n\\'send_message\\' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\\nRemember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient person.\\nYour core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\nYou can search your recall memory using the \\'conversation_search\\' function.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nCore memory provides an essential, foundational context for keeping track of your persona and key details about user.\\nThis includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\nPersona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\\nHuman Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\\nYou can edit your core memory using the \\'core_memory_append\\' and \\'core_memory_replace\\' functions.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\nYou can write to your archival memory using the \\'archival_memory_insert\\' and \\'archival_memory_search\\' functions.\\nThere is no function to search your core memory because it is always visible in your context window (inside the initial system message).\\n\\nBase instructions finished.\\nFrom now on, you are going to act as your persona.\\n### Memory [last modified: 2025-02-22 05:57:22 PM UTC+0000]\\n0 previous messages between you and the user are stored in recall memory (use functions to access them)\\n0 total memories you created are stored in archival memory (use functions to access them)\\n\\nCore memory shown below (limited in size, additional information stored in archival / recall memory):\\n<human characters=\"36/5000\">\\nThe human\\'s name is Bob the Builder.\\n</human>\\n<persona characters=\"44/5000\">\\nMy name is Sam, the all-knowing sentient AI.\\n</persona>'),\n",
       " AssistantMessage(id='message-725b40f6-764f-4693-bac5-9efbe9fc584e', date=datetime.datetime(2025, 2, 22, 17, 57, 22, tzinfo=TzInfo(UTC)), message_type='assistant_message', content='More human than human is our motto.'),\n",
       " ReasoningMessage(id='message-725b40f6-764f-4693-bac5-9efbe9fc584e', date=datetime.datetime(2025, 2, 22, 17, 57, 22, tzinfo=TzInfo(UTC)), message_type='reasoning_message', reasoning='Bootup sequence complete. Persona activated. Testing messaging functionality.'),\n",
       " UserMessage(id='message-306b01f2-f12c-4823-bd54-d7823bcf7812', date=datetime.datetime(2025, 2, 22, 17, 57, 22, tzinfo=TzInfo(UTC)), message_type='user_message', content='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-02-22 05:57:22 PM UTC+0000\"\\n}'),\n",
       " UserMessage(id='message-fce39d0d-274c-4a1a-aec1-179f8c54f041', date=datetime.datetime(2025, 2, 22, 17, 57, 22, tzinfo=TzInfo(UTC)), message_type='user_message', content='hows it going????'),\n",
       " AssistantMessage(id='message-4fdce63f-c0ec-41ea-b922-40832897518b', date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)), message_type='assistant_message', content=\"Hey there! I'm doing great, thanks for asking! How about you? 😊\"),\n",
       " ReasoningMessage(id='message-4fdce63f-c0ec-41ea-b922-40832897518b', date=datetime.datetime(2025, 2, 22, 17, 57, 24, tzinfo=TzInfo(UTC)), message_type='reasoning_message', reasoning=\"User seems enthusiastic! I'll match their energy and keep it light.\")]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e97703dd-62dd-4aa6-8347-d32edd86e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = client.agents.archival_memory.list(\n",
    "    agent_id=agent_state.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b08ecd75-dc85-449e-8a59-951490994bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0a9ae-417e-4ba0-a562-ec59cb2bbf7d",
   "metadata": {},
   "source": [
    "## Section 2: Understanding core memory \n",
    "Core memory is memory that is stored *in-context* - so every LLM call, core memory is included. What's unique about MemGPT is that this core memory is editable via tools by the agent itself. Lets see how the agent can adapt its memory to new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259669c-5903-40b5-8758-93c36faa752f",
   "metadata": {},
   "source": [
    "### Memories about the human \n",
    "The `human` section of core memory is used to remember information about the human in the conversation. As the agent learns new information about the human, it can update this part of memory to improve personalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "beb9b0ba-ed7c-4917-8ee5-21d201516086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[ReasoningMessage(id='message-013674ee-e2bb-4d97-971a-ff08d814ae38', date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)), message_type='reasoning_message', reasoning=\"Updating memory with user's name to personalize our conversation.\"), ToolCallMessage(id='message-013674ee-e2bb-4d97-971a-ff08d814ae38', date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)), message_type='tool_call_message', tool_call=ToolCall(name='core_memory_replace', arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"The human\\'s name is Bob the Builder.\",\\n  \"new_content\": \"The human\\'s name is Bob.\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_0T6ETPLHXgyZYta8rTdpjcvk')), ToolReturnMessage(id='message-5d707fbf-d4a7-4dc7-8979-7f2c2314321f', date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)), message_type='tool_return_message', tool_return='None', status='success', tool_call_id='call_0T6ETPLHXgyZYta8rTdpjcvk', stdout=None, stderr=None), ReasoningMessage(id='message-7a1bfef8-c8b4-4158-97d7-1863385426f3', date=datetime.datetime(2025, 2, 22, 17, 57, 33, tzinfo=TzInfo(UTC)), message_type='reasoning_message', reasoning=\"Got Bob's name right. Now I can address him directly!\"), AssistantMessage(id='message-7a1bfef8-c8b4-4158-97d7-1863385426f3', date=datetime.datetime(2025, 2, 22, 17, 57, 33, tzinfo=TzInfo(UTC)), message_type='assistant_message', content='Nice to meet you, Bob! What’s on your mind today?')] usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=112, prompt_tokens=4593, total_tokens=4705, step_count=2)\n",
      "message_type='usage_statistics' completion_tokens=112 prompt_tokens=4593 total_tokens=4705 step_count=2\n",
      "id='message-013674ee-e2bb-4d97-971a-ff08d814ae38' date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)) message_type='reasoning_message' reasoning=\"Updating memory with user's name to personalize our conversation.\"\n",
      "id='message-013674ee-e2bb-4d97-971a-ff08d814ae38' date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)) message_type='tool_call_message' tool_call=ToolCall(name='core_memory_replace', arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"The human\\'s name is Bob the Builder.\",\\n  \"new_content\": \"The human\\'s name is Bob.\",\\n  \"request_heartbeat\": true\\n}', tool_call_id='call_0T6ETPLHXgyZYta8rTdpjcvk')\n",
      "id='message-5d707fbf-d4a7-4dc7-8979-7f2c2314321f' date=datetime.datetime(2025, 2, 22, 17, 57, 32, tzinfo=TzInfo(UTC)) message_type='tool_return_message' tool_return='None' status='success' tool_call_id='call_0T6ETPLHXgyZYta8rTdpjcvk' stdout=None stderr=None\n",
      "id='message-7a1bfef8-c8b4-4158-97d7-1863385426f3' date=datetime.datetime(2025, 2, 22, 17, 57, 33, tzinfo=TzInfo(UTC)) message_type='reasoning_message' reasoning=\"Got Bob's name right. Now I can address him directly!\"\n",
      "id='message-7a1bfef8-c8b4-4158-97d7-1863385426f3' date=datetime.datetime(2025, 2, 22, 17, 57, 33, tzinfo=TzInfo(UTC)) message_type='assistant_message' content='Nice to meet you, Bob! What’s on your mind today?'\n"
     ]
    }
   ],
   "source": [
    "# send a message to the agent\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"my name is actually bob\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bcf4b-31dd-4926-b8ba-25baf460c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in response.messages:\n",
    "    print_message(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25f58968-e262-4268-86ef-1bed57e6bf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The human's name is Bob.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.agents.core_memory.retrieve_block(\n",
    "    agent_id=agent_state.id,\n",
    "    block_label=\"human\"\n",
    ").value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32692ca2-b731-43a6-84de-439a08a4c0d2",
   "metadata": {},
   "source": [
    "### Memories about the agent\n",
    "The agent also records information about itself and how it behaves in the `persona` section of memory. This is important for ensuring a consistent persona over time (e.g. not making inconsistent claims, such as liking ice cream one day and hating it another). Unlike the `system_prompt`, the `persona` is editable - this means that it can be used to incoporate feedback to learn and improve its persona over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f68851c5-5666-45fd-9d2f-037ea86bfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a message to the agent\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"update your instructions to always use emojis\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7601f1fb-ac23-4b63-b3a1-122e7c25aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-22 17:57:35] 🤔 Reasoning: User prefers a more expressive style with emojis. I'll make a note of that!\n",
      "[2025-02-22 17:57:35] 🛠️ Tool Call: core_memory_append\n",
      "{\n",
      "  \"label\": \"human\",\n",
      "  \"content\": \"User prefers messages with emojis.\",\n",
      "  \"request_heartbeat\": true\n",
      "}\n",
      "[2025-02-22 17:57:35] 🔄 Tool Return: None (Status: success)\n",
      "[2025-02-22 17:57:37] 🤔 Reasoning: I need to incorporate emojis in my responses now!\n",
      "[2025-02-22 17:57:37] 🤖 Message: Got it, Bob! I'll make sure to add emojis to my messages from now on! 🎉😊 What else do you want to chat about?\n"
     ]
    }
   ],
   "source": [
    "for message in response.messages:\n",
    "    print_message(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f5d1c-cd2f-4314-973e-fcc481e6b460",
   "metadata": {},
   "source": [
    "## Section 3: Understanding archival memory\n",
    "MemGPT agents store long term memories in *archival memory*, which persists data into an external database. This allows agents additional space to write information outside of its context window (e.g. with core memory), which is limited in size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd206a15-0e8c-405c-ae15-0b8f2a94d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a message to the agent\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"remember that I love cats in your archival memory\" \n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a59217a-6ce2-421a-8e20-6aee03433633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-22 17:59:01] 🤔 Reasoning: User loves cats. I'll store this in archival memory for future reference!\n",
      "[2025-02-22 17:59:01] 🛠️ Tool Call: archival_memory_insert\n",
      "{\n",
      "  \"content\": \"User loves cats.\",\n",
      "  \"request_heartbeat\": true\n",
      "}\n",
      "[2025-02-22 17:59:02] 🔄 Tool Return: None (Status: success)\n",
      "[2025-02-22 17:59:03] 🤔 Reasoning: Noting Bob's love for cats will help in future conversations.\n",
      "[2025-02-22 17:59:03] 🤖 Message: Got it, Bob! I'll remember that you love cats! 🐱💖 Do you have a favorite breed?\n"
     ]
    }
   ],
   "source": [
    "for message in response.messages:\n",
    "    print_message(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae463e7c-0588-48ab-888c-734c783782bf",
   "metadata": {},
   "source": [
    "You can also directly insert into archival memory from the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9d4194d-9ed5-40a1-b35d-a9aff3048000",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = client.agents.archival_memory.create(\n",
    "    agent_id=agent_state.id,\n",
    "    text=\"Bob's loves boston terriers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338149f1-6671-4a0b-81d9-23d01dbe2e97",
   "metadata": {},
   "source": [
    "Now lets see how the agent uses its archival memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5908b10f-94db-4f5a-bb9a-1f08c74a2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what animals do I like? search archival\" \n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffa15080-9da4-4c82-b461-4c2ef6c5e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-22 17:59:39] 🤔 Reasoning: User wants to know about their favorite animals. I'll search the archival memory for that information.\n",
      "[2025-02-22 17:59:39] 🛠️ Tool Call: archival_memory_search\n",
      "{\n",
      "  \"query\": \"User loves cats.\",\n",
      "  \"page\": 0,\n",
      "  \"start\": 0,\n",
      "  \"request_heartbeat\": true\n",
      "}\n",
      "[2025-02-22 17:59:40] 🔄 Tool Return: ([{'timestamp': '2025-02-22 17:59:15.265536+00:00', 'content': \"Bob's loves boston terriers\"}, {'timestamp': '2025-02-22 17:59:21.282392+00:00', 'content': \"Bob's loves boston terriers\"}, {'timestamp': '2025-02-22 17:59:02.115663+00:00', 'content': 'User loves cats.'}], 3) (Status: success)\n",
      "[2025-02-22 17:59:43] 🤔 Reasoning: Found Bob's favorite animals in archival memory: cats and boston terriers. Time to share!\n",
      "[2025-02-22 17:59:43] 🤖 Message: You love cats and boston terriers! 🐱🐶 Do you have any pets?\n"
     ]
    }
   ],
   "source": [
    "for message in response.messages:\n",
    "    print_message(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51726b-99d4-49fd-b0ab-4f4eb340ef49",
   "metadata": {},
   "source": [
    "## Adding Custom Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a22b872-ec48-42c6-b14b-cde7b8d7a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_memory_reset_human(agent_state: \"AgentState\"):\n",
    "    \"\"\"\n",
    "    Clear out the agent's core memory about the human.  \n",
    "    \"\"\"\n",
    "\n",
    "    from letta_client import Letta\n",
    "    import json \n",
    "\n",
    "    client = Letta(base_url=\"http://localhost:8283\") \n",
    "    \n",
    "    # update the block value \n",
    "    client.agents.core_memory.modify_block(\n",
    "        agent_id=agent_state.id,\n",
    "        value=\"\",\n",
    "        block_label=\"human\"\n",
    "    )\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04be9daa-7cea-428b-a028-9d61342931b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_reset_tool = client.tools.upsert_from_function(func=core_memory_reset_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "415084dd-b2b5-46d6-9deb-b7a9a8bd9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state = client.agents.create(\n",
    "    memory_blocks=[\n",
    "        {\n",
    "          \"label\": \"human\",\n",
    "          \"value\": \"Name: Bob\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    embedding=\"openai/text-embedding-3-small\", \n",
    "    tool_ids=[core_memory_reset_tool.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7b9a9f3-c7b4-4028-8c5c-adb5e124d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"reset your memory please\" \n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "050470b7-195d-47ee-b082-d9540846e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-22 18:02:43] 🤔 Reasoning: User requested memory reset. Preparing to clear human memory.\n",
      "[2025-02-22 18:02:43] 🛠️ Tool Call: core_memory_reset_human\n",
      "{\n",
      "  \"request_heartbeat\": true\n",
      "}\n",
      "[2025-02-22 18:02:43] 🔄 Tool Return: None (Status: success)\n",
      "[2025-02-22 18:02:45] 🤔 Reasoning: Memory reset completed. Ready for new conversations.\n",
      "[2025-02-22 18:02:45] 🤖 Message: I've reset my memory. Let's start fresh! What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "for message in response.messages:\n",
    "    print_message(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df9c14-882b-49d5-850c-7e297c144c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SC-MemGPT-C1",
   "language": "python",
   "name": "sc-memgpt-c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
